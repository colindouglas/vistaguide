---
title: "Nova Scotia Real Estate"
# author: "Colin Douglas"
date: Last Updated `r format(Sys.time(), "%b %d, %Y at %H:%M %p")`
always_allow_html: true
permalink: /real-estate/
layout: page
excerpt: Aggregated data on Nova Scotia real estate listings
comments: false
output: 
  html_document:
    toc: true
  md_document:
    variant: markdown_phpextra
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.path="img/")

library(tidyverse)
library(lubridate)
library(kableExtra)
library(broom)
source("setup.R")
source("price-gradient.R")

```

```{r Read in data, define regions}

listings_all <- read_csv("data/listings-clean.csv", col_types = cols())

listings <- listings_all %>%
  filter(!is.na(type), !is.na(status)) %>%
  arrange(datetime) %>%
  # Keep only the unique rows, because sometimes things get posted more than once
  distinct(mls_no, pid, price, status, .keep_all = TRUE) %>%
  mutate(status = factor(status, levels = names(status_colors)),
         type = factor(case_when(
           type == "Single Family" ~ "Single Family", 
           type %in% c("Duplex", "Triplex", "Fourplex") ~ "Multiplex",
           grepl("unit", type, ignore.case = TRUE) ~ "Multiplex",
           TRUE ~ word(type, 1)), levels = type_order),
         street_address = address,
         address = ifelse(is.na(unit), address, paste0(unit, "-", address)))

last_dt <- as_datetime(max(listings$datetime, na.rm = TRUE))

```
# Summary
These are aggregate statistics on real estate listings in Nova Scotia. Each evening, I scrape real estate listings from *the popular real estate sites* and compile them into one big data set. I first started collecting data on April 6, 2020.

This dataset contains **`r nrow(listings_all)` data points** on **`r listings$mls_no %>% unique() %>% length()` unique listings**. The last update was performed on **`r format(last_dt, "%A %B %d, %Y at %I:%M %p")`**, and scraped **`r nrow(filter(listings, datetime > Sys.Date() - hours(18)))`** different listing pages.

# Volume

This figure shows the net change in inventory in a given day. It is calculated as new listings with a status of "For Sale" minus the sum of new listings with the statuses "Sold", "Expired", "Withdrawn", and "Cancelled". Listings with a status of "Pending" are ignored. The dashed line denotes the 7 day rolling mean of market entrances per day.
```{r Balance in Listings, fig.width = 10, fig.height = 4}
listing_type <- c("For Sale" = "enter", 
                  "Sold" = "exit", 
                  "Defunct" = "exit",
                  "Pending" = NA, 
                  "Withdrawn" = "exit", 
                  "Cancelled" = "exit", 
                  "Expired" = "exit")

volume_changes <- listings %>%
  mutate(status = as.character(status), 
         status_type = listing_type[status]) %>%
    filter(status != "Pending", !is.na(status_type)) %>%
  group_by(date = as_date(datetime), status_type) %>% 
  summarize(N = n()) %>%
  pivot_wider(id_cols = date, names_from = "status_type", values_from = "N", values_fill = list(N = 0)) %>%
  mutate(net_change = enter - exit)
  
volume_plot <- listings %>%
  filter(status != "Pending") %>%
  group_by(date = as_date(datetime), status) %>%
  summarize(count = n()) %>%
  mutate(status = as.character(status),
    status_type = listing_type[status],
         count = case_when(
           status_type == "enter" ~ count,
           status_type == "exit" ~ -count
         )) %>%
  ggplot(aes(x = date, y = count)) +
  geom_col(aes(fill = status), na.rm = TRUE) +
  scale_fill_manual(values = status_colors, guide = FALSE) +
  geom_text(data = volume_changes, aes(y = enter + max(enter) * 0.075, label = enter), size = 3) +
  geom_text(data = volume_changes, aes(y = -(exit + max(exit) * 0.075), label = exit), size = 3) +
  geom_line(data = volume_changes, aes(y = zoo::rollmean(net_change, 7, na.pad=TRUE, align = "right")), lty = 2, na.rm = TRUE) +
  labs(x = "Date", y = "Change in Active Listings") +
  scale_x_date(limits = c(Sys.Date() - days(45), Sys.Date() + days(1)))

suppressWarnings(print(volume_plot))

```

# Pricing
## Spread by Region
```{r Price per Area on vs. Off, fig.width=8, fig.height=8}

# Clean up the listings, bin each location into something meaningful
hrm_vs_other <- listings %>%
  filter(price < 1E6, between(sqft_mla, 450, 4000), # Nothing too fancy, thanks
         type %in% c("Single Family", "Condominium"))


# Fit each (location bin, type) to a linear model, extract the coefficients and make a pretty box for the graph
sqft_fits <- hrm_vs_other %>%
  group_by(loc_bin, type) %>%
  do(fit = lm(.$price ~ .$sqft_mla)) %>%
  mutate(slope = fit$coefficients[2],
         intercept = fit$coefficients[1],
         pretty = paste0("Base: ", scales::dollar(signif(intercept, 3)),
                         ifelse(is.na(slope), "", paste("\nPer Sq. ft.: ", scales::dollar(signif(slope, 3))))))

hrm_vs_other %>%
  arrange(desc(datetime)) %>%
  mutate(days_since = as.numeric(ymd(list_date) - ymd("2020-04-01"))) %>%
  filter(days_since >= 0) %>%
  ggplot(aes(x = sqft_mla, y = price)) +
  geom_label(data = sqft_fits, aes(label = pretty),
             x = -Inf, y = Inf, hjust = 0, vjust = 1,
             size = 3) +
  geom_point(aes(color = days_since), na.rm = TRUE, alpha = 0.1) +
  labs(color = "", x = "Square Footage (MLS)", y = "List Price") +
  facet_grid(loc_bin ~ type) +
  scale_color_viridis_c(option = "plasma", 
                        direction = 1,
                        name = "Days Since\n2020-04-01") +
  scale_y_continuous(labels = scales::dollar) +
  geom_smooth(method = "lm", formula = y ~ x, na.rm = TRUE, color = "darkgrey")

```

## Price Trends
Trends in the price per unit area of different property types in different location binds. No line is drawn until there are at least 20 data points in a facet, but still be cautious of overfitting.

```{r Price per Square Foot Over Time, fig.width = 10, fig.height = 4}

sqft_vs_time <- listings %>%    
  filter(status %in% c("For Sale", "Sold"),
         loc_bin != "Rest of Province",
         between(sqft_mla, 450, 4000),
         !is.na(type))

svt_fit <- sqft_vs_time %>%
  group_by(status, type, loc_bin) %>%
  filter(n() > 20) %>%
  ungroup() %>%
  mutate(loc_bin = factor(loc_bin, levels = c("Halifax Peninsula", "Halifax, Off Peninsula", "Dartmouth", "HRM, Other")))


sqft_plot <- svt_fit  %>% 
  ggplot(aes(x = datetime, y = price/sqft_mla)) +
  geom_point(aes(color = type), alpha = 0.2) +
  facet_grid(status ~ loc_bin, scales = "free_y") +
  geom_smooth(data = svt_fit, method = "loess", formula = y~x, aes(color = type), level = 0.01, lwd = 0.7, span = 1) +
  labs(x = "List Date") +
  scale_color_brewer(name = "", palette = "Set1", direction = -1) +
  scale_y_continuous(name = "$/Sq. Ft.") +
  coord_cartesian(ylim = c(75, 550)) +
  theme(legend.position = "bottom")

suppressWarnings(print(sqft_plot))

```


## Sale Price and Re-List Price

* "Sale Price" refers to the change in price of a property when it's marked as "Sold" vs it's listing price as "For Sale" or "Pending"
* "Re-List Price" refers to the change in price of a property between two consecutive "For Sale" events
* The labels on the RHS of the plot show the average over the last seven days

```{r price changes over time, fig.width = 8, fig.height = 4}
change_plot <- listings %>%
  group_by(pid) %>%
  filter(n() > 1) %>%
  arrange(datetime) %>%
  mutate(price_change = (price - lag(price))/lag(price)) %>%
  filter(!(is.na(price_change)),
         abs(price_change) < 0.5)

change_labels <- change_plot %>%
  group_by(status) %>%
  filter(datetime > now() - weeks(1),
         status %in% c("Sold", "For Sale")) %>%
  summarize(mean_change = mean(price_change))

change_plot %>%
  ggplot(aes(x = datetime, y = price_change)) +
  geom_point(data = filter(change_plot, price_change != 0), aes(color = status), alpha = 0.1) +
  geom_smooth(data = filter(change_plot, status %in% c("Sold", "For Sale")), 
              formula = y ~ x,
              method = "loess", 
              aes(color = status), 
              level = 0,
              lwd = 0.5) +
  scale_color_manual(values = status_colors, name = "") +
  scale_y_continuous(name = "Price Change Since Last Event", labels = scales::percent, minor_breaks = seq(-1, 1, by = .05)) +
  geom_hline(yintercept = 0, lty = 2, lwd = 0.25) +
  scale_alpha_continuous(guide = FALSE) +
  scale_x_datetime(limits = c(as_datetime(NA), now() + days(1)), name = "Scrape Date") +
  ggrepel::geom_label_repel(data = change_labels, x = now(), 
                            aes(y = mean_change, color = status, label = scales::percent(mean_change, accuracy = 0.01)), 
                            hjust = 0, direction = 'y') +
  coord_cartesian(ylim = c(-.1, .1))

```

## Assessment vs. Sale Price
Assessment vs. sale prices for properties listed as "Sold". The dashed line is identity (i.e., selling for assessment value) while the dotted lines represent selling for 1.5x, 2x, 3x, and 10x over assessment

```{r Assessment vs. Sale Price, fig.width = 8, fig.height = 5}

listings %>%
  filter(status == "Sold",
         assessment < 1E6, price < 2E6,
         assessment_year == "2020") %>%
  ggplot(aes(x = assessment, y = price)) +
  geom_point(aes(color = loc_bin), na.rm = TRUE, alpha = 0.2) +
  scale_color_viridis_d(option = "plasma", name = "", end = 7/9) +
  scale_x_continuous(name = "Assessment (2020)", labels = scales::dollar) +
  scale_y_continuous(name = "Sale Price", labels = scales::dollar) +
  geom_abline(slope = c(1, 1.5, 2, 3, 10), 
              alpha = 1/c(1, 2, 3, 4, 5),
              lty = c(2, 3, 3, 3, 3)) 
```

## Peninsula Heatmap
```{r peninsula heatmap, fig.width = 7.5, fig.height = 7}
suppressWarnings(hfx_heatmap)
```

# Listing vs. Sale Price
These are the 20 most recently-listed addresses that have a price change in their history as well as a listing marked as "Sold".
```{r Price Changes}
listings_with_change <- listings %>%
  filter(status != "Pending") %>%
  group_by(pid) %>%
  distinct(status, price, .keep_all = TRUE) %>%
  filter(length(unique(status)) > 1, # Has more than one datapoint
         status == "Sold") %>% # Either it has a "Sold" data point or it has a price change
  arrange(list_date) %>%
  pull(pid)

close_order <- listings %>%
  filter(pid %in% listings_with_change) %>%
  group_by(pid, address) %>%
  summarize(list_date = max(datetime)) %>%
  arrange(list_date) %>%
  pull(address) %>%
  unique()

col_num <- 4
last_listings <- 20 
figure_rows <- last_listings %/% col_num + 1
```

```{r Price Changes Graph, fig.width = 10, fig.height = figure_rows + 2}

pid_to_address <- listings %>%
  group_by(pid) %>%
  summarize(address = head(address, 1))

pid_labeller <- pid_to_address$address
names(pid_labeller) <- as.character(pid_to_address$pid)

listings %>%
  filter(pid %in% tail(unique(listings_with_change), last_listings),
         price < 1E6) %>%
  arrange(list_date) %>%
  mutate(address = factor(address, levels = close_order)) %>%
  ggplot(aes(x = as_date(datetime), y = price)) +
  geom_line(aes(group = pid, color = status), lwd = 2, alpha = 0.5) +
  geom_blank(aes(y = price * 1.05)) +  geom_blank(aes(y = price * 0.95)) + # Add a least a bit of scale to the price changes
  geom_point(aes(color = status), size = 4) +
  scale_color_manual(values = status_colors, name = "") +
  scale_x_date(name = "List Date") +
  facet_wrap(~ pid, scales = "free_y", ncol = col_num, labeller = labeller(pid = pid_labeller)) +
  ggrepel::geom_text_repel(aes(label = paste0("$", round(price/1000), "k"))) + 
  scale_y_continuous(name = "Price", breaks = seq(0, 1E6, by = 10000), labels = c()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), axis.ticks = element_blank())
```

# Sale Price Model
```{r, Model setup, include=FALSE}
source("pricing-model.R")
rows_print <- 15
```

## Undervalued by Model
Top `r rows_print` properties that are either undervalued by the model, or terrible deals.
```{r overvalued properties, rows.print = 10}

print_listing_table <- function(df) {
  df %>%
    mutate(scrape_date = as_date(datetime),
      street = ifelse(is.na(unit), street, paste0(unit, "-", street)),
           address_link = cell_spec(street,"html", link = url),
           value_score = round(xsv_z * 100),
           complex_prd = scales::dollar(complex_prd),
            price =  scales::dollar(price),
           loc_bin = str_trunc(case_when(
             postal_first %in% names(peninsula_codes) ~ peninsula_codes[postal_first],
             TRUE ~ city
           ), 16)) %>%
    select(`Date` = scrape_date,
           Address = address_link,
           Location = loc_bin,
           `Pred. Sale Price` = complex_prd,
           `Listing Price` = price,
           `Sq. Ft` = sqft_tla,
           `Value Score` = value_score) %>%
    kable("html", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("hover", "condensed"))
  
}

test_set %>%
  arrange(xsv_z) %>%
  filter(list_date > (today() - days(14))) %>%
  head(rows_print) %>%
  print_listing_table(.)
```

## Overvalued by Model
Top `r rows_print` properties that are either overvalued by the model, or great deals!
```{r undervalued properties, rows.print = 10}

test_set %>%
  arrange(-xsv_z) %>%
  filter(list_date > (today() - days(14))) %>%
  head(rows_print) %>%
  print_listing_table(.)
```

## Listings on Gladstone
All of the listings on Gladstone St in Halifax
```{r Listings at on Gladstone}
test_set %>%
  arrange(desc(datetime)) %>%
  filter(grepl("Gladstone", address)) %>%
  print_listing_table(.)

```

## Listings on the Peninsula
The last 15 listings on the Halifax Peninsula by scrape date
```{r Listings on the Peninsula}
test_set %>%
  arrange(desc(datetime)) %>%
  filter(loc_bin == "Halifax Peninsula" | loc_bin %in% peninsula_codes) %>%
  head(15) %>%
  print_listing_table(.)

```