---
title: "n.s. real estate"
always_allow_html: true
comments: false
layout: page
permalink: /real-estate/
output: 
  html_document:
    toc: true
  md_document:
    variant: markdown-tex_math_dollars
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.path="img/")
options(dplyr.summarise.inform = FALSE)

library(tidyverse)
library(lubridate)
library(kableExtra)
library(broom)
library(tsibble)
source("setup-constants.R")
source("connect-db.R")

# Take a datetime and return a readable string describing the approximate time
bin_datetime <- function(datetime) {
  datetime <- as_datetime(datetime)
  breaks <- hour(hm("00:00", "6:00", "12:00", "16:00", "21:00", "23:59"))
  labels <- c("very early in the morning", 
              "in the morning", 
              "in the afternoon", 
              "in the evening",
              "late in the evening")
  
  time_bin <- cut(hour(datetime), 
                  breaks, labels, 
                  include.lowest=TRUE)
  
  date <- format(as_date(datetime), format = "%A %B %-d, %Y")
  
  paste(time_bin, "on", date)
}
```

```{r Read in data from db, calculate summary stats for header}

properties <- tbl(dbcon, "properties")
updates <- tbl(dbcon, "updates") 
geocode <- tbl(dbcon, "geocode")

listings_all <- updates %>%
  left_join(properties, by = "prop_id") %>%
  left_join(geocode, by = "address")

listings <- listings_all %>%
  filter(!is.na(type), !is.na(status)) %>%
  arrange(datetime) %>%
  collect() %>%
  mutate(datetime = ymd_hms(datetime),
         street_address = address,
         address = ifelse(is.na(unit), address, paste0(unit, "-", address)))

unique_updates <- updates %>% 
  summarize(n = n()) %>% 
  collect() %>%
  pull()

unique_properties <- properties %>% 
  summarize(n = n()) %>% 
  collect() %>%
  pull()

last_update <- max(listings$datetime)

new_today <- listings %>%
  filter(datetime > Sys.Date() - hours(24)) %>%
  nrow()

```
# Summary
These are aggregate statistics on real estate listings in Nova Scotia. Twice a day, I scrape real estate listings from *the internet* and compile them into one big data set. I first started collecting data on April 6, 2020.

This dataset contains **`r unique_updates` rows** describing **`r unique_properties` unique listings**. The last update was performed **`r bin_datetime(last_update)`**, and discovered **`r new_today`** new listings.

# Volume

This figure shows the net change in inventory in a given day. It is calculated as new listings with a status of "For Sale" minus the sum of new listings with the statuses "Sold", "Expired", "Withdrawn", and "Cancelled". Listings with a status of "Pending" are ignored. The dashed line denotes the 7 day rolling mean of market entrances per day.

## Last Month
```{r Balance in Listings, fig.width = 10, fig.height = 4}
listing_type <- c("For Sale" = "enter", 
                  "Sold" = "exit", 
                  "Defunct" = "exit",
                  "Pending" = NA, 
                  "Withdrawn" = "exit", 
                  "Cancelled" = "exit", 
                  "Expired" = "exit")

volume_changes <- listings %>%
  mutate(status = as.character(status), 
         status_type = listing_type[status]) %>%
    filter(status != "Pending", !is.na(status_type)) %>%
  group_by(date = as_date(datetime), status_type) %>% 
  summarize(N = n()) %>%
  pivot_wider(id_cols = date, names_from = "status_type", values_from = "N", values_fill = list(N = 0)) %>%
  mutate(net_change = enter - exit)
  
volume_plot_daily <- listings %>%
  filter(status != "Pending") %>%
  group_by(date = as_date(datetime), status) %>%
  summarize(count = n()) %>%
  mutate(status = as.character(status),
    status_type = listing_type[status],
         count = case_when(
           status_type == "enter" ~ count,
           status_type == "exit" ~ -count
         )) %>%
  ggplot(aes(x = date, y = count)) +
  geom_col(aes(fill = status), na.rm = TRUE) +
  scale_fill_manual(values = status_colors, guide = FALSE) +
  geom_text(data = volume_changes, aes(y = enter + max(enter) * 0.075, label = enter), size = 3) +
  geom_text(data = volume_changes, aes(y = -(exit + max(exit) * 0.075), label = exit), size = 3) +
  geom_line(data = volume_changes, aes(y = zoo::rollmean(net_change, 7, na.pad=TRUE, align = "right")), lty = 2, na.rm = TRUE) +
  labs(x = "Date", y = "Change in Active Listings") +
  scale_x_date(limits = c(Sys.Date() - days(31), Sys.Date() + days(1)))

suppressWarnings(print(volume_plot_daily))

```

## Weekly
```{r Balance Trend Overall, fig.width = 10, fig.height = 4}

listings_ts <- as_tsibble(listings, key = mls_no, index = datetime)

volume_changes_weekly <- listings_ts %>%
  mutate(status = as.character(status), 
         status_type = listing_type[status]) %>%
  filter(status != "Pending", !is.na(status_type)) %>%
  group_by(status_type) %>% 
  index_by(year_week = ~ yearweek(.)) %>%
  summarize(N = n()) %>%
  pivot_wider(id_cols = year_week, names_from = "status_type", values_from = "N", values_fill = list(N = 0)) %>%
  mutate(
    net_change = case_when(
      year_week == yearweek(today()) ~ NA_integer_,  #  Don't calc for the current week so no trendline
      TRUE ~ enter - exit),
    year_week = as_date(year_week))
  
volume_plot_daily <- listings_ts %>%
  mutate(status = as.character(status), 
         status_type = listing_type[status]) %>%
  filter(status != "Pending", !is.na(status_type)) %>%
  group_by(status) %>%
  index_by(year_week = ~ yearweek(.)) %>%
  summarize(count = n()) %>%
  mutate(status = as.character(status),
    status_type = listing_type[status],
         count = case_when(
           status_type == "enter" ~ count,
           status_type == "exit" ~ -count
         )) %>%
  mutate(year_week = as_date(year_week)) %>%
  ggplot(aes(x = year_week, y = count)) +
  geom_col(aes(fill = status), na.rm = TRUE) +
  scale_fill_manual(values = status_colors, guide = FALSE) +
  geom_text(data = volume_changes_weekly, aes(y = enter + max(enter) * 0.075, label = enter), size = 3) +
  geom_text(data = volume_changes_weekly, aes(y = -(exit + max(exit) * 0.075), label = exit), size = 3) +
  geom_line(data = volume_changes_weekly, aes(y = net_change, group = 1), lty = 2, na.rm = TRUE) +
  scale_x_date(name = "Week (Starting On)", date_labels = "%-m/%-d", date_breaks = "1 week") +
  labs(y = "Change in Active Listings")

suppressWarnings(print(volume_plot_daily))

```

# Pricing
## Spread by Region
```{r Price per Area on vs. Off, fig.width=8, fig.height=8}

# Clean up the listings, bin each location into something meaningful
hrm_vs_other <- listings %>%
  filter(price < 1E6, between(sqft_mla, 450, 4000), # Nothing too fancy, thanks
         type %in% c("Single Family", "Condominium"))


# Fit each (location bin, type) to a linear model, extract the coefficients and make a pretty box for the graph
sqft_fits <- hrm_vs_other %>%
  group_by(loc_bin, type) %>%
  do(fit = lm(.$price ~ .$sqft_mla)) %>%
  mutate(slope = fit$coefficients[2],
         intercept = fit$coefficients[1],
         pretty = paste0("Base: ", scales::dollar(signif(intercept, 3)),
                         ifelse(is.na(slope), "", paste("\nPer Sq. ft.: ", scales::dollar(signif(slope, 3))))))

hrm_vs_other %>%
  arrange(desc(datetime)) %>%
  mutate(days_since = as.numeric(ymd(list_date) - ymd("2020-04-01"))) %>%
  filter(days_since >= 0) %>%
  ggplot(aes(x = sqft_mla, y = price)) +
  geom_label(data = sqft_fits, aes(label = pretty),
             x = -Inf, y = Inf, hjust = 0, vjust = 1,
             size = 3) +
  geom_point(aes(color = days_since), na.rm = TRUE, alpha = 0.1) +
  labs(color = "", x = "Square Footage (MLS)", y = "List Price") +
  facet_grid(loc_bin ~ type) +
  scale_color_viridis_c(option = "plasma", 
                        direction = 1,
                        name = "Days Since\n2020-04-01") +
  scale_y_continuous(labels = scales::dollar) +
  geom_smooth(method = "lm", formula = y ~ x, na.rm = TRUE, color = "darkgrey")

```

## Price Trends
Trends in the price per unit area of different property types in different location binds. No line is drawn until there are at least 20 data points in a facet, but still be cautious of overfitting.

```{r Price per Square Foot Over Time, fig.width = 8, fig.height = 7}

sqft_vs_time <- listings %>%    
  filter(status %in% c("For Sale", "Sold"),
         type %in% c("Single Family", "Condominium"),
         loc_bin != "Rest of Province",
         between(sqft_mla, 450, 4000),
         !is.na(type))

svt_fit <- sqft_vs_time %>%
  group_by(status, type, loc_bin) %>%
  filter(n() > 20) %>%
  ungroup() %>%
  mutate(loc_bin = factor(loc_bin, levels = c("Halifax Peninsula", "Halifax, Off Peninsula", "Dartmouth", "HRM, Other")))


sqft_plot <- svt_fit  %>% 
  ggplot(aes(x = as_date(datetime), y = price/sqft_mla)) +
  geom_point(aes(color = status), alpha = 0.1) +
  facet_grid(loc_bin ~ type, scales = "free") +
  geom_smooth(data = svt_fit, method = "loess", formula = y~x, aes(color = status), level = 0.01, lwd = 0.7, span = 1) +
scale_x_date(name = "List Date", date_labels = "%-m/%-d") +
  scale_color_manual(values = status_colors, name = "") +
  scale_y_continuous(name = "$/Sq. Ft.") +
  coord_cartesian(ylim = c(75, 550))

suppressWarnings(print(sqft_plot))

```


## Sale Price and Re-List Price

* "Sale Price" refers to the change in price of a property when it's marked as "Sold" vs it's listing price as "For Sale" or "Pending"
* "Re-List Price" refers to the change in price of a property between two consecutive "For Sale" events
* The labels on the RHS of the plot show the average over the last seven days

```{r price changes over time, fig.width = 8, fig.height = 4}
change_plot <- listings %>%
  filter(loc_bin != "Rest of Province") %>%
  group_by(pid) %>%
  filter(n() > 1) %>%
  arrange(datetime) %>%
  mutate(price_change = (price - lag(price))/lag(price)) %>%
  filter(!(is.na(price_change)),
         abs(price_change) < 0.5)

change_labels <- change_plot %>%
  group_by(status) %>%
  filter(datetime > now() - weeks(1),
         status %in% c("Sold", "For Sale")) %>%
  summarize(mean_change = mean(price_change))

change_plot %>%
  ggplot(aes(x = datetime, y = price_change)) +
  geom_point(data = filter(change_plot, price_change != 0), aes(color = status), alpha = 0.1) +
  geom_smooth(data = filter(change_plot, status %in% c("Sold", "For Sale")), 
              formula = y ~ x,
              method = "loess", 
              aes(color = status), 
              level = 0,
              lwd = 0.5) +
  scale_color_manual(values = status_colors, name = "") +
  scale_y_continuous(name = "Price Change Since Last Event", labels = scales::percent, minor_breaks = seq(-1, 1, by = .05)) +
  geom_hline(yintercept = 0, lty = 2, lwd = 0.25) +
  scale_alpha_continuous(guide = FALSE) +
  scale_x_datetime(limits = c(as_datetime(NA), now() + days(1)), name = "Scrape Date") +
  ggrepel::geom_label_repel(data = change_labels, x = now(), 
                            aes(y = mean_change, color = status, label = scales::percent(mean_change, accuracy = 0.01)), 
                            hjust = 0, direction = 'y') +
  coord_cartesian(ylim = c(-.01, .01))

```

## Assessment vs. Sale Price
Assessment vs. sale prices for properties listed as "Sold". The dashed line is identity (i.e., selling for assessment value) while the dotted lines represent selling for 1.5x, 2x, 3x, and 10x over assessment

```{r Assessment vs. Sale Price, fig.width = 8, fig.height = 5}

listings %>%
  filter(status == "Sold",
         assessment < 1E6, price < 2E6,
         assessment_year == "2020") %>%
  ggplot(aes(x = assessment, y = price)) +
  geom_point(aes(color = loc_bin), na.rm = TRUE, alpha = 0.2) +
  scale_color_viridis_d(option = "plasma", name = "", end = 7/9) +
  scale_x_continuous(name = "Assessment (2020)", labels = scales::dollar) +
  scale_y_continuous(name = "Sale Price", labels = scales::dollar) +
  geom_abline(slope = c(1, 1.5, 2, 3, 10), 
              alpha = 1/c(1, 2, 3, 4, 5),
              lty = c(2, 3, 3, 3, 3)) 
```

## Peninsula Heatmap
There is nothing surprising in this heatmap, but it's a nice visualization of what most people already know intuitively.

```{r peninsula heatmap, fig.width = 7.5, fig.height = 7}

suppressMessages({
  source("price-gradient.R")
  hfx_heatmap
})

```

# Listing vs. Sale Price
These are the 20 most recently-listed addresses that have a price change in their history as well as a listing marked as "Sold".
```{r Price Changes}
listings_with_change <- listings %>%
  filter(status != "Pending") %>%
  group_by(pid) %>%
  distinct(status, price, .keep_all = TRUE) %>%
  filter(length(unique(status)) > 1, # Has more than one datapoint
         status == "Sold") %>% # Either it has a "Sold" data point or it has a price change
  arrange(list_date) %>%
  pull(pid)

close_order <- listings %>%
  filter(pid %in% listings_with_change) %>%
  group_by(pid, address) %>%
  summarize(list_date = max(datetime)) %>%
  arrange(list_date) %>%
  pull(pid) %>%
  unique()

col_num <- 4
last_listings <- 20 
figure_rows <- last_listings %/% col_num + 1
```

```{r Price Changes Graph, fig.width = 10, fig.height = figure_rows + 2}

pid_to_address <- listings %>%
  group_by(pid) %>%
  summarize(address = head(address, 1))

pid_labeller <- pid_to_address$address
names(pid_labeller) <- as.character(pid_to_address$pid)

listings %>%
  mutate(pid = factor(pid, levels = close_order)) %>%
  distinct(address, pid, status, price, .keep_all = TRUE) %>%
  filter(pid %in% tail(unique(listings_with_change), last_listings),
         price < 1E6) %>%
  arrange(list_date) %>%
  mutate(address = factor(address, levels = close_order)) %>%
  ggplot(aes(x = as_date(datetime), y = price)) +
  geom_line(aes(group = pid, color = status), lwd = 2, alpha = 0.5) +
  geom_blank(aes(y = price * 1.05)) +  geom_blank(aes(y = price * 0.95)) + # Add a least a bit of scale to the price changes
  geom_point(aes(color = status), size = 4) +
  scale_color_manual(values = status_colors, name = "") +
  scale_x_date(name = "List Date", date_minor_breaks = "1 day", date_breaks = "7 days", date_labels = "%-m/%-d") +
  facet_wrap(~ pid, scales = "free_y", ncol = col_num, labeller = labeller(pid = pid_labeller)) +
  ggrepel::geom_text_repel(aes(label = paste0("$", round(price/1000), "k"))) + 
  scale_y_continuous(name = "Price", breaks = seq(0, 1E6, by = 10000), labels = c()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), axis.ticks = element_blank())
```

# Recent Properties for Sale
These tables only list properties where their last event is being listed as "For Sale". They will disappear from this list once they've been listed as Pending or Sold.

```{r, Model setup, include=FALSE}
source("pricing-model.R")
rows_print <- 15

print_listing_table <- function(df) {
  
  df %>%
    distinct(pid, .keep_all = TRUE) %>%
    mutate(scrape_date = as_date(datetime),
      street = ifelse(is.na(unit), street, paste0(unit, "-", street)),
           address_link = cell_spec(street,"html", link = url),
           value_score = round(xsv_z * 100),
           complex_prd = scales::dollar(complex_prd),
            price =  scales::dollar(price),
           loc_bin = str_trunc(case_when(
             postal_first %in% names(peninsula_codes) ~ peninsula_codes[postal_first],
             TRUE ~ city
           ), 16)) %>%
    select(`Date` = scrape_date,
           Address = address_link,
           Location = loc_bin,
           `Pred. Sale Price` = complex_prd,
           `Listing Price` = price,
           `Sq. Ft` = sqft_mla,
           `Value Score` = value_score) %>%
    kable("html", escape = FALSE) %>%
    kable_styling(bootstrap_options = c("hover", "condensed"))
  
}
```

## Listings on the Peninsula

The last 15 listings on the Halifax Peninsula by scrape date
```{r Listings on the Peninsula}
test_set %>%
  arrange(desc(datetime)) %>%
  filter(loc_bin == "Halifax Peninsula" | loc_bin %in% peninsula_codes) %>%
  head(15) %>%
  print_listing_table(.)

```

## Undervalued by Model
Top `r rows_print` properties that are either undervalued by the model, or terrible deals.

```{r Undervalued by Model}
test_set %>%
  arrange(xsv_z) %>%
  filter(list_date > (today() - days(14))) %>%
  head(rows_print) %>%
  print_listing_table(.)
```

## Overvalued by Model
Top `r rows_print` properties that are either overvalued by the model, or great deals!
```{r undervalued properties, rows.print = 10}

test_set %>%
  arrange(-xsv_z) %>%
  filter(list_date > (today() - days(14))) %>%
  head(rows_print) %>%
  print_listing_table(.)
```

## Listings on Gladstone
The listings on Gladstone St. in Halifax that are still active.
```{r Listings at on Gladstone}
test_set %>%
  arrange(desc(datetime)) %>%
  filter(grepl("Gladstone", address)) %>%
  print_listing_table(.)

```